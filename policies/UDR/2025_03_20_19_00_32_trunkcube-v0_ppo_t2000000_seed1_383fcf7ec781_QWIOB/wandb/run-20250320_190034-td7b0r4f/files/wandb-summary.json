{"train_mean_reward": 39.88359405999999, "timestep": 2009196, "_timestamp": 1742899483.1509535, "distance": 12.55447067428482, "_runtime": 405849.03820347786, "_step": 200, "episode": {"r": 18.785864, "l": 100, "t": 125899.796444}, "terminal_observation": [0.684, -4.358, 36.163, -12.41425, -30.14175, 51.38175, -29.85575, -65.486, 80.24325, -5.585, -80.68875, 118.4985, 80.0, -100.0, 65.0, 58.546, -82.819, 65.007, 0.0, -0.357, 0.0, 0.934], "train_std_reward": 12.242514523642765, "which_best_model": "best", "test_mean_reward": 65.76879675, "test_std_reward": 3.228099928919826, "_wandb": {"runtime": 409999}}