{"train_mean_reward": 48.11605886, "timestep": 2009196, "_timestamp": 1743264774.7657876, "distance": 9.445043171376097, "_runtime": 359573.5540175438, "_step": 200, "episode": {"r": 42.405491, "l": 100, "t": 298611.158469}, "terminal_observation": [1.0127335997183202, -14.29081074902568, 28.534173737168352, 6.217059720018231, -36.04079184770364, 54.845914170429104, 28.536290385122335, -80.55897349496458, 72.7091651379479, 25.337034054339277, -98.47940468925518, 121.29671927486332, 80.0, -100.0, 65.0, 76.6298645511526, -85.9942989680187, 64.40789193880659, 0.011461466745720239, 0.16620127039187318, -0.003117091571017278, 0.9860203122858586], "train_std_reward": 11.844407660853973, "which_best_model": "best", "test_mean_reward": 49.12189231, "test_std_reward": 2.3939366892174725, "_wandb": {"runtime": 362793}}